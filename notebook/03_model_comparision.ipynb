{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "03_model_comparison.ipynb\n",
    "\n",
    "Comparison of OCR Pipelines:\n",
    "- YOLO + CRNN (Ours)\n",
    "- YOLO + TrOCR\n",
    "- EasyOCR (End-to-End)\n",
    "\"\"\"\n",
    "\n",
    "USE_COLAB = True\n",
    "\n",
    "if USE_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    PROJECT_ROOT = \"/content/drive/MyDrive/Information-Extraction-from-Image\"\n",
    "else:\n",
    "    PROJECT_ROOT = os.path.abspath(\".\")\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Install dependencies\n",
    "# ===============================\n",
    "!pip install -r {PROJECT_ROOT}/requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Standard Library\n",
    "# ===============================\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# ===============================\n",
    "# Third-party Libraries\n",
    "# ===============================\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from ultralytics import YOLO\n",
    "import ultralytics\n",
    "\n",
    "import easyocr\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = os.path.join(PROJECT_ROOT, \"datasets/SceneTrialTrain\")\n",
    "CACHE_DIR = os.path.join(PROJECT_ROOT, \"cache\")\n",
    "MODEL_DIR = os.path.join(PROJECT_ROOT, \"model\")\n",
    "\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(CACHE_DIR, \"val_data.pkl\"), \"rb\") as f:\n",
    "    cache = pickle.load(f)\n",
    "\n",
    "val_yolo_data = cache[\"val_yolo_data\"]\n",
    "image_paths = cache[\"image_paths\"]\n",
    "image_labels = cache[\"image_labels\"]\n",
    "bounding_boxes = cache[\"bounding_boxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipeline import (\n",
    "    inference_yolo_crnn,\n",
    "    inference_yolo_trocr,\n",
    "    inference_easyocr,\n",
    ")\n",
    "\n",
    "from src.evaluation import (\n",
    "    evaluate_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__DUsL59z01o"
   },
   "source": [
    "Comparison of 3 models on the test dataset:\n",
    "- **YOLO + CRNN (Ours)**\n",
    "- **YOLO + TrOCR**\n",
    "- **EasyOCR (End-to-End)**\n",
    "\n",
    "Evaluation based on:\n",
    "\n",
    "- Character Accuracy\n",
    "\n",
    "- Word Accuracy\n",
    "\n",
    "- Inference Speed\n",
    "\n",
    "With 2 confidence thresholds: **0.3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwCqXiDEM0PM"
   },
   "source": [
    "#1. Vocabulary & CRNN Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = \"0123456789abcdefghijklmnopqrstuvwxyz-\"\n",
    "BLANK_CHAR = \"-\"\n",
    "\n",
    "char_to_idx = {c: i + 1 for i, c in enumerate(sorted(CHARS))}\n",
    "idx_to_char = {i: c for c, i in char_to_idx.items()}\n",
    "\n",
    "VOCAB_SIZE = len(CHARS)\n",
    "\n",
    "CRNN_CONFIG = {\n",
    "    \"hidden_size\": 256,\n",
    "    \"n_layers\": 3,\n",
    "    \"dropout\": 0.2,\n",
    "    \"unfreeze_layers\": 3,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dhc-3IPiM50N"
   },
   "source": [
    "#2. Load YOLO + CRNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.recognition import CRNN\n",
    "\n",
    "yolo_model_path = os.path.join(MODEL_DIR, \"yolo/best.pt\")\n",
    "crnn_model_path = os.path.join(MODEL_DIR, \"cnn/ocr_crnn.pt\")\n",
    "\n",
    "yolo_det = YOLO(yolo_model_path)\n",
    "print(\"YOLO loaded\")\n",
    "\n",
    "crnn_model = CRNN(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    **CRNN_CONFIG,\n",
    ").to(DEVICE)\n",
    "\n",
    "crnn_model.load_state_dict(\n",
    "    torch.load(crnn_model_path, map_location=DEVICE)\n",
    ")\n",
    "crnn_model.eval()\n",
    "print(\"CRNN loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ossQvSC9NZqd"
   },
   "source": [
    "#3. Load TrOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading TrOCR...\")\n",
    "trocr_processor = TrOCRProcessor.from_pretrained(\n",
    "    \"microsoft/trocr-base-printed\"\n",
    ")\n",
    "trocr_model = VisionEncoderDecoderModel.from_pretrained(\n",
    "    \"microsoft/trocr-base-printed\"\n",
    ").to(DEVICE)\n",
    "trocr_model.eval()\n",
    "print(\"TrOCR loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWugvy-6OC4e"
   },
   "source": [
    "#4. Load EasyOCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easyocr_reader = easyocr.Reader(\n",
    "    [\"en\"], gpu=torch.cuda.is_available()\n",
    ")\n",
    "print(\"EasyOCR loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BU5ibYA6OJ73"
   },
   "source": [
    "#5. Build Test Dataset (from YOLO Val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = val_yolo_data[:50]\n",
    "test_data = []\n",
    "\n",
    "for img_rel_path, _ in test_samples:\n",
    "    img_path = os.path.join(DATASET_DIR, img_rel_path)\n",
    "\n",
    "    for p, labels, bbs in zip(image_paths, image_labels, bounding_boxes):\n",
    "        if p != img_rel_path:\n",
    "            continue\n",
    "\n",
    "        for bb, label in zip(bbs, labels):\n",
    "            x, y, w, h = map(int, bb)\n",
    "            test_data.append(\n",
    "                {\n",
    "                    \"image_path\": img_path,\n",
    "                    \"bbox\": (x, y, w, h),\n",
    "                    \"label\": label,\n",
    "                }\n",
    "            )\n",
    "        break\n",
    "\n",
    "print(\n",
    "    f\"Prepared {len(test_data)} text regions \"\n",
    "    f\"from {len(test_samples)} images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1InPIVo7OkQG"
   },
   "source": [
    "#6. CRNN Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crnn_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((100, 420)),\n",
    "        transforms.Grayscale(1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJJ6E4eROnzb"
   },
   "source": [
    "#7. Evaluation (Confidence = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# Test with confidence threshold 0.3\n",
    "conf_threshold = 0.3\n",
    "print(f\"\\n\\n{'#'*80}\")\n",
    "print(f\"# EVALUATION WITH CONFIDENCE THRESHOLD = {conf_threshold}\")\n",
    "print(f\"{'#'*80}\\n\")\n",
    "\n",
    "# Evaluate YOLO + CRNN\n",
    "yolo_crnn_infer = partial(\n",
    "    inference_yolo_crnn,\n",
    "    yolo_det=yolo_det,\n",
    "    crnn_transform=crnn_transform,\n",
    "    crnn_inference=crnn_model,\n",
    "    idx_to_char=idx_to_char,\n",
    ")\n",
    "\n",
    "results_yolo_crnn = evaluate_model(\n",
    "    yolo_crnn_infer,\n",
    "    test_data,\n",
    "    \"YOLO + CRNN (Ours)\",\n",
    "    conf_threshold=conf_threshold\n",
    ")\n",
    "\n",
    "# Evaluate YOLO + TrOCR\n",
    "yolo_trocr_infer = partial(\n",
    "    inference_yolo_trocr,\n",
    "    yolo_det=yolo_det,\n",
    "    trocr_processor=trocr_processor,\n",
    "    trocr_model=trocr_model,\n",
    ")\n",
    "\n",
    "results_yolo_trocr = evaluate_model(\n",
    "    yolo_trocr_infer,\n",
    "    test_data,\n",
    "    \"YOLO + TrOCR\",\n",
    "    conf_threshold=conf_threshold\n",
    ")\n",
    "\n",
    "# Evaluate EasyOCR (end-to-end)\n",
    "easyocr_infer = partial(\n",
    "    inference_easyocr,\n",
    "    easyocr_reader=easyocr_reader,\n",
    ")\n",
    "\n",
    "results_easyocr = evaluate_model(\n",
    "    easyocr_infer,\n",
    "    test_data,\n",
    "    \"EasyOCR (End-to-End)\",\n",
    "    conf_threshold=conf_threshold\n",
    ")\n",
    "\n",
    "# Store results for comparison\n",
    "results_03 = [results_yolo_crnn, results_yolo_trocr, results_easyocr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8OBbM_oOvN1"
   },
   "source": [
    "#8. Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display comparison results for confidence threshold 0.3\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"COMPARISON RESULTS - CONFIDENCE THRESHOLD = 0.3\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "results = [r for r in results_03 if r]\n",
    "if len(results) > 0:\n",
    "    df_03 = pd.DataFrame(results)\n",
    "    df_03 = df_03[['model', 'char_acc', 'word_acc', 'avg_time', 'matched_regions']]\n",
    "    df_03.columns = ['Model', 'Char Acc (%)', 'Word Acc (%)', 'Speed (s/img)', 'Matched Regions']\n",
    "    print(df_03.to_string(index=False))\n",
    "    best_char_03 = df_03.loc[df_03['Char Acc (%)'].idxmax(), 'Model']\n",
    "    best_word_03 = df_03.loc[df_03['Word Acc (%)'].idxmax(), 'Model']\n",
    "\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Confidence 0.3 - Best Char Acc: {best_char_03} | Best Word Acc: {best_word_03}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(results_03) > 0:\n",
    "    # Visualize results for confidence threshold 0.3\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
    "    df = df_03\n",
    "\n",
    "    # Character Accuracy\n",
    "    axes[0].bar(df['Model'], df['Char Acc (%)'], color=colors)\n",
    "    axes[0].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    axes[0].set_title('Character Accuracy (Conf=0.3)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylim([0, 100])\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    for i, v in enumerate(df['Char Acc (%)']):\n",
    "        axes[0].text(i, v + 2, f'{v:.1f}%', ha='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "    # Word Accuracy\n",
    "    axes[1].bar(df['Model'], df['Word Acc (%)'], color=colors)\n",
    "    axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    axes[1].set_title('Word Accuracy (Conf=0.3)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_ylim([0, 100])\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    for i, v in enumerate(df['Word Acc (%)']):\n",
    "        axes[1].text(i, v + 2, f'{v:.1f}%', ha='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "    # Speed\n",
    "    axes[2].bar(df['Model'], df['Speed (s/img)'], color=colors)\n",
    "    axes[2].set_ylabel('Time (seconds)', fontsize=12)\n",
    "    axes[2].set_title('Speed (Conf=0.3)', fontsize=14, fontweight='bold')\n",
    "    axes[2].grid(axis='y', alpha=0.3)\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    max_speed = float(df['Speed (s/img)'].max())\n",
    "    axes[2].set_ylim(0, max_speed * 1.3)\n",
    "\n",
    "    for i, v in enumerate(df['Speed (s/img)']):\n",
    "        axes[2].text(i, v + v * 0.05, f'{v:.3f}s', ha='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No results to visualize!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions from 3 models on 2 sample images\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SAMPLE PREDICTIONS VISUALIZATION (2 Sample Images)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Select 2 random sample images\n",
    "sample_indices = random.sample(range(len(test_data)), min(2, len(test_data)))\n",
    "\n",
    "for sample_idx in sample_indices:\n",
    "    sample_img_path = test_data[sample_idx]['image_path']\n",
    "\n",
    "    print(f\"\\n{'─'*100}\")\n",
    "    print(f\"SAMPLE IMAGE {sample_idx + 1}: {sample_img_path}\")\n",
    "    print(f\"{'─'*100}\")\n",
    "\n",
    "    # Get ground truth labels for this image\n",
    "    gt_labels = [item['label'] for item in test_data if item['image_path'] == sample_img_path]\n",
    "    print(f\"Ground Truth Labels: {gt_labels}\")\n",
    "    print(f\"Total regions in this image: {len(gt_labels)}\\n\")\n",
    "\n",
    "    # Get predictions with confidence threshold 0.3\n",
    "    preds_crnn = inference_yolo_crnn(sample_img_path, yolo_det, crnn_transform, crnn_model, idx_to_char, conf_threshold=0.3)\n",
    "    preds_trocr = inference_yolo_trocr(sample_img_path, yolo_det, trocr_processor, trocr_model, conf_threshold=0.3)\n",
    "    preds_easyocr = inference_easyocr(sample_img_path, easyocr_reader, conf_threshold=0.3)\n",
    "\n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "    for idx, (preds, title) in enumerate([\n",
    "        (preds_crnn, 'YOLO + CRNN (Ours)'),\n",
    "        (preds_trocr, 'YOLO + TrOCR'),\n",
    "        (preds_easyocr, 'EasyOCR (End-to-End)')\n",
    "    ]):\n",
    "        img = cv2.imread(sample_img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        for pred in preds:\n",
    "            x, y, w, h = pred['bbox']\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "            # Add text\n",
    "            text = pred['text']\n",
    "            conf = pred['confidence']\n",
    "            label = f\"{text} ({conf:.2f})\"\n",
    "\n",
    "            # Background for text\n",
    "            (text_w, text_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
    "            cv2.rectangle(img, (x, y-text_h-5), (x+text_w, y), (0, 255, 0), -1)\n",
    "            cv2.putText(img, label, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(title, fontsize=14, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print detection results\n",
    "    print(f\"  YOLO+CRNN detected: {len(preds_crnn)} regions\")\n",
    "    for i, pred in enumerate(preds_crnn):\n",
    "        print(f\"    {i+1}. {pred['text']} (conf: {pred['confidence']:.3f})\")\n",
    "\n",
    "    print(f\"\\n  YOLO+TrOCR detected: {len(preds_trocr)} regions\")\n",
    "    for i, pred in enumerate(preds_trocr):\n",
    "        print(f\"    {i+1}. {pred['text']} (conf: {pred['confidence']:.3f})\")\n",
    "\n",
    "    print(f\"\\n  EasyOCR detected: {len(preds_easyocr)} regions\")\n",
    "    for i, pred in enumerate(preds_easyocr):\n",
    "        print(f\"    {i+1}. {pred['text']} (conf: {pred['confidence']:.3f})\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
